<!--by Rubens Flinco & Vitor Camargo-->
<!DOCTYPE html>
<html>
  

<head>
  <script type="text/javascript" src="js/jquery-2.1.1.min.js"></script>
  <script src="dist/face-api.js"></script>
  <script src="js/commons.js"></script>
  <link rel="stylesheet" href="css/styles.css">
  <link rel="stylesheet" href="css/materialize.css">
  <script src="js/materialize.min.js"></script>
</head>

<body>
  <div class="bg">
  <div id="navbar" style="display: none;"></div>
  <div id="consoleHTML" style="display:block!important;"></div>
  <div class="center center-content page-container">
    <div class="margin center">
      <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
      <canvas id="overlay" />
    </div>
    <div class="row side-by-side">
      </div>
      </div>
    </div>
    <footer>
    <br>
      <div class="center">
        <img src="img/fclogowhite.png" width="150" />
      </div>
    </footer>
    

  <script>
    let scoreThreshold = 0.1
    let sizeType = '320'

    let minFaceSize = 100
    let maxDistance = 0.50
    let minConfidence = 0.9

    var consoleAdd = 0;
    var consoleLimit = 0;

    let modelLoaded = false

    let forwardTimes = []


    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
    }

    function onIncreaseThreshold() {
      scoreThreshold = Math.min(faceapi.round(scoreThreshold + 0.1), 1.0)
      $('#scoreThreshold').val(scoreThreshold)
    }

    function onDecreaseThreshold() {
      scoreThreshold = Math.max(faceapi.round(scoreThreshold - 0.1), 0.1)
      $('#scoreThreshold').val(scoreThreshold)
    }

    function onSizeTypeChanged(e, c) {
      sizeType = e.target.value
      $('#sizeType').val(sizeType)
    }

    async function onPlay(videoEl) {


      const { width, height } = faceapi.getMediaDimensions(videoEl)
      const canvas = $('#overlay').get(0)
      canvas.width = width
      canvas.height = height

      const forwardParams = {
        inputSize: parseInt(sizeType),
        scoreThreshold
      }

      const mtcnnParams = {
        minFaceSize
      }

      const ts = Date.now()
      result = await faceapi.tinyYolov2(videoEl, forwardParams)
      updateTimeStats(Date.now() - ts)

      //faceapi.drawDetection('overlay', result.map(det => det.forSize(width, height)))
      
      const fullFaceDescriptions = (await faceapi.allFacesMtcnn(videoEl, mtcnnParams))
        .map(fd => fd.forSize(width, height))
      updateTimeStats(Date.now() - ts)
      result = await faceapi.tinyYolov2(videoEl, forwardParams)
      updateTimeStats(Date.now() - ts)

      fullFaceDescriptions.forEach(({ detection, landmarks, descriptor }) => {
        //faceapi.drawDetection('overlay', [detection], { withScore: false })
        //faceapi.drawLandmarks('overlay', landmarks.forSize(width, height), { lineWidth: 4, color: 'red' })
        const bestMatch = getBestMatch(trainDescriptorsByClass, descriptor)
        const text = `${bestMatch.distance < maxDistance ? bestMatch.className : 'unkown'} (${bestMatch.distance})`
        const name = `${bestMatch.distance < maxDistance ? bestMatch.className : 'unkown'}`
        const { x, y, height: boxHeight } = detection.getBox()

        if(consoleAdd > consoleLimit){
        $('#consoleHTML').html('');
        consoleAdd = 0;
        $('#consoleHTML').append("Reconhecido: "+text+"<br>");
        consoleAdd++;
        }else{
        $('#consoleHTML').append("Desconhecido: "+text+"<br>");
        consoleAdd++;
        }

        // faceapi.drawText(
        //   canvas.getContext('2d'),
        //   x,
        //   y + boxHeight,
        //   text,
        //   Object.assign(faceapi.getDefaultDrawOptions(), { color: 'red', fontSize: 24 })
        // )
      })
      setTimeout(() => onPlay(videoEl),)
    }
    async function loadNetWeights(uri) {
      return new Float32Array(await (await fetch(uri)).arrayBuffer())
    }
    async function run() {
      await faceapi.loadMtcnnModel('/')
      await faceapi.loadFaceRecognitionModel('/')

      // init reference data, e.g. compute a face descriptor for each class
      trainDescriptorsByClass = await initTrainDescriptorsByClass(faceapi.recognitionNet)

      await faceapi.loadTinyYolov2Model('/')
      modelLoaded = true

      const videoEl = $('#inputVideo').get(0)
      navigator.getUserMedia(
        { video: {} },
        stream => videoEl.srcObject = stream,
        err => console.error(err)
      )

      onPlay($('#inputVideo').get(0))
      $('#loader').hide()
    }

    $(document).ready(function () {

      const sizeTypeSelect = $('#sizeType')
      sizeTypeSelect.val(sizeType)
      sizeTypeSelect.on('change', onSizeTypeChanged)
      sizeTypeSelect.material_select()
      run()
    })
  </script>
  </div>
</body>

</html>